{"version":3,"file":"index.js","mappings":";;AAAA;AACA;;;;;;ACDA;;ACAA;;ACAA;;;;;;AAMA;AAmHA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;;;ACtIA;;AAEA;AACA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;;;ACbA;;;;;;;;AAQA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAoBA;;;;;AAKA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;;;AC/JA;;;;;;;;;;;;;;;;;;;;;;;AAuBA;AAGA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAiBA;;;;;;;AAOA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAaA;;;;;;;AAOA;AACA;AAKA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACvOA;;ACAA;;;;;;;;;AASA;AAEA;AACA;AAEA;AACA;AACA;AAEA;;;;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;;;AC3DA;;;;;;;;;;AAUA;AAEA;AAEA;AAoBA;;;;AAIA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAiBA;;;;;;AAMA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAaA;;;;;;;;;;;AAWA;AACA;AAGA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;;;ACvRA;;;;;;;;;;;;;;;;AAgBA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAkBA;;;;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AAqBA;AACA;AAEA;;;;;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;;;;;;;;;;;;;AAeA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;;;AClTA;;;;;;;;AAQA;AAEA;AAEA;AACA;AACA;AACA","sources":["../webpack/runtime/compat","../external node-commonjs \"child_process\"","../external node-commonjs \"path\"",".././src/types.ts",".././src/utils.ts",".././src/github.ts",".././src/reducer.ts","../external node-commonjs \"fs\"",".././src/paths.ts",".././src/state.ts",".././src/poller.ts",".././src/poller-entry.ts"],"sourcesContent":["\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = new URL('.', import.meta.url).pathname.slice(import.meta.url.match(/^file:\\/\\/\\/\\w:/) ? 1 : 0, -1) + \"/\";","const __WEBPACK_NAMESPACE_OBJECT__ = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"child_process\");","const __WEBPACK_NAMESPACE_OBJECT__ = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"path\");","/**\n * Boundary types for github-api-usage-monitor v1\n * Generated from spec/spec.json\n *\n * These types define the contracts between modules.\n * Do not modify without updating the spec.\n */\n\n// -----------------------------------------------------------------------------\n// RateLimitSample\n// Single sample from /rate_limit for one bucket\n// -----------------------------------------------------------------------------\n\nexport interface RateLimitSample {\n  /** Maximum requests allowed in the window */\n  limit: number;\n  /** Requests used in the current window */\n  used: number;\n  /** Requests remaining in the current window */\n  remaining: number;\n  /** Unix epoch seconds when the window resets */\n  reset: number;\n}\n\n// -----------------------------------------------------------------------------\n// RateLimitResponse\n// Full response from GET /rate_limit\n// -----------------------------------------------------------------------------\n\nexport interface RateLimitResponse {\n  /** Rate limit data per bucket (core, search, graphql, etc.) */\n  resources: Record<string, RateLimitSample>;\n  /** Deprecated alias for resources.core */\n  rate: RateLimitSample;\n}\n\n// -----------------------------------------------------------------------------\n// BucketState\n// Per-bucket reducer state\n// -----------------------------------------------------------------------------\n\nexport interface BucketState {\n  /** Unix epoch seconds of the last seen reset timestamp */\n  last_reset: number;\n  /** Last observed 'used' value */\n  last_used: number;\n  /** Accumulated usage across the job duration */\n  total_used: number;\n  /** Number of times the reset boundary was crossed */\n  windows_crossed: number;\n  /** Count of unexpected deltas (used decreased without reset change) */\n  anomalies: number;\n  /** ISO timestamp of last observation (for debugging) */\n  last_seen_ts: string;\n  /** Last observed limit */\n  limit: number;\n  /** Last observed remaining */\n  remaining: number;\n}\n\n// -----------------------------------------------------------------------------\n// ReducerState\n// Global reducer state persisted to state.json\n// -----------------------------------------------------------------------------\n\nexport interface ReducerState {\n  /** Per-bucket state keyed by bucket name */\n  buckets: Record<string, BucketState>;\n  /** ISO timestamp when monitoring started */\n  started_at_ts: string;\n  /** ISO timestamp when monitoring stopped (null if still running) */\n  stopped_at_ts: string | null;\n  /** ISO timestamp when poller process started (null before poller runs) */\n  poller_started_at_ts: string | null;\n  /** Polling interval in seconds */\n  interval_seconds: number;\n  /** Total number of successful polls */\n  poll_count: number;\n  /** Total number of failed poll attempts */\n  poll_failures: number;\n  /** Last error message (null if no errors) */\n  last_error: string | null;\n}\n\n// -----------------------------------------------------------------------------\n// SummaryData\n// Data passed to output renderer for summary generation\n// -----------------------------------------------------------------------------\n\nexport interface SummaryData {\n  /** Final reducer state */\n  state: ReducerState;\n  /** Job duration in seconds */\n  duration_seconds: number;\n  /** Warning messages to display */\n  warnings: string[];\n}\n\n// -----------------------------------------------------------------------------\n// Configuration\n// -----------------------------------------------------------------------------\n\nexport interface Config {\n  /** GitHub token for API authentication */\n  token: string;\n  /** Polling interval in seconds */\n  interval_seconds: number;\n}\n\n// -----------------------------------------------------------------------------\n// Platform info\n// -----------------------------------------------------------------------------\n\nexport type Platform = 'linux' | 'darwin' | 'win32' | 'unknown';\n\nexport interface PlatformInfo {\n  platform: Platform;\n  supported: boolean;\n  reason?: string;\n}\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\nexport const POLL_INTERVAL_SECONDS = 30;\nexport const STATE_DIR_NAME = 'github-api-usage-monitor';\nexport const STATE_FILE_NAME = 'state.json';\nexport const PID_FILE_NAME = 'poller.pid';\n\n/** Timeout for fetch requests to GitHub API (milliseconds) */\nexport const FETCH_TIMEOUT_MS = 10000;\n\n/** Maximum poller lifetime as defense-in-depth (6 hours in milliseconds) */\nexport const MAX_LIFETIME_MS = 6 * 60 * 60 * 1000;\n","/**\n * Checks if input is an object and not null.\n */\nexport const isARealObject = (value: unknown): value is Record<string, unknown> => {\n  return typeof value === 'object' && value !== null;\n};\n\n/**\n * Checks if input is a string or null.\n * Used for validating optional string fields in state.\n */\nexport const isStringOrNull = (value: unknown): value is string | null => {\n  return value === null || typeof value === 'string';\n};\n","/**\n * GitHub API Client\n * Layer: infra\n *\n * Provided ports:\n *   - github.fetchRateLimit\n *\n * Fetches rate limit data from the GitHub API.\n */\n\nimport type { RateLimitResponse, RateLimitSample } from './types';\nimport { FETCH_TIMEOUT_MS } from './types';\nimport { isARealObject } from './utils';\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\nconst RATE_LIMIT_URL = 'https://api.github.com/rate_limit';\nconst USER_AGENT = 'github-api-usage-monitor/1.0';\n\n// -----------------------------------------------------------------------------\n// Port: github.fetchRateLimit\n// -----------------------------------------------------------------------------\n\nexport interface FetchRateLimitResult {\n  success: true;\n  data: RateLimitResponse;\n  timestamp: string;\n}\n\nexport interface FetchRateLimitError {\n  success: false;\n  error: string;\n  timestamp: string;\n}\n\nexport type FetchRateLimitOutcome = FetchRateLimitResult | FetchRateLimitError;\n\n/**\n * Fetches rate limit data from GitHub API.\n *\n * @param token - GitHub token for authentication\n * @returns Rate limit response or error\n */\nexport async function fetchRateLimit(token: string): Promise<FetchRateLimitOutcome> {\n  const timestamp = new Date().toISOString();\n\n  // Set up abort controller with timeout to prevent indefinite hangs\n  const controller = new AbortController();\n  const timeoutId = setTimeout(() => controller.abort(), FETCH_TIMEOUT_MS);\n\n  try {\n    const response = await fetch(RATE_LIMIT_URL, {\n      signal: controller.signal,\n      method: 'GET',\n      headers: {\n        'Authorization': `Bearer ${token}`,\n        'Accept': 'application/vnd.github+json',\n        'User-Agent': USER_AGENT,\n        'X-GitHub-Api-Version': '2022-11-28',\n      },\n    });\n\n    clearTimeout(timeoutId);\n\n    if (!response.ok) {\n      const statusText = response.statusText || 'Unknown error';\n      return {\n        success: false,\n        error: `HTTP ${response.status}: ${statusText}`,\n        timestamp,\n      };\n    }\n\n    const raw: unknown = await response.json();\n    const parsed = parseRateLimitResponse(raw);\n\n    if (!parsed) {\n      return {\n        success: false,\n        error: 'Failed to parse rate limit response',\n        timestamp,\n      };\n    }\n\n    return {\n      success: true,\n      data: parsed,\n      timestamp,\n    };\n  } catch (err) {\n    clearTimeout(timeoutId);\n\n    const error = err as Error;\n\n    // Handle abort error specifically (timeout)\n    if (error.name === 'AbortError') {\n      return {\n        success: false,\n        error: `Request timeout: GitHub API did not respond within ${FETCH_TIMEOUT_MS}ms`,\n        timestamp,\n      };\n    }\n\n    return {\n      success: false,\n      error: `Network error: ${error.message}`,\n      timestamp,\n    };\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Helpers\n// -----------------------------------------------------------------------------\n\n/**\n * Validates that a sample has the expected shape.\n * Used for defensive parsing.\n */\nexport function isValidSample(sample: unknown): sample is RateLimitSample {\n  if (!isARealObject(sample)) {\n    return false;\n  }\n  const requiredFields = ['limit', 'used', 'remaining', 'reset'];\n  return requiredFields.every(field => typeof sample[field] === 'number');\n}\n\n/**\n * Parses raw API response into typed RateLimitResponse.\n * Returns null if parsing fails.\n */\nexport function parseRateLimitResponse(raw: unknown): RateLimitResponse | null {\n  if (!isARealObject(raw) || !isARealObject(raw['resources'])) {\n    return null;\n  }\n\n  const resources: Record<string, RateLimitSample> = {};\n\n  for (const [key, value] of Object.entries(raw['resources'])) {\n    if (!isValidSample(value)) {\n      return null;\n    }\n    resources[key] = value;\n  }\n\n  // Use rate if valid, otherwise fall back to resources.core\n  const rawRate = raw['rate'];\n  if (isValidSample(rawRate)) {\n    return { resources, rate: rawRate };\n  }\n\n  const coreResource = resources['core'];\n  if (coreResource) {\n    return { resources, rate: coreResource };\n  }\n\n  return null;\n}\n","/**\n * Reducer\n * Layer: core\n *\n * Provided ports:\n *   - reducer.update\n *   - reducer.initBucket\n *\n * Pure business logic for rate-limit reduction.\n * Maintains constant-space per-bucket state.\n *\n * Algorithm (per poll, per bucket):\n *   if bucket not initialized:\n *     initialize with current reset/used\n *   else if reset == last_reset (same window):\n *     delta = used - last_used\n *     if delta < 0: anomaly (do not subtract)\n *     else: total_used += delta\n *   else (new window):\n *     windows_crossed += 1\n *     total_used += used (include post-reset usage)\n *     last_reset = reset\n *   last_used = used\n */\n\nimport type { ReducerState, BucketState, RateLimitSample, RateLimitResponse } from './types';\nimport { POLL_INTERVAL_SECONDS } from './types';\n\n// -----------------------------------------------------------------------------\n// Port: reducer.initBucket\n// -----------------------------------------------------------------------------\n\n/**\n * Initializes a new bucket state from the first sample.\n */\nexport function initBucket(sample: RateLimitSample, timestamp: string): BucketState {\n  return {\n    last_reset: sample.reset,\n    last_used: sample.used,\n    total_used: 0, // First sample is baseline, not counted\n    windows_crossed: 0,\n    anomalies: 0,\n    last_seen_ts: timestamp,\n    limit: sample.limit,\n    remaining: sample.remaining,\n  };\n}\n\n// -----------------------------------------------------------------------------\n// Port: reducer.update\n// -----------------------------------------------------------------------------\n\nexport interface UpdateResult {\n  /** Updated bucket state */\n  bucket: BucketState;\n  /** Delta applied this poll (0 if anomaly or boundary) */\n  delta: number;\n  /** True if an anomaly was detected */\n  anomaly: boolean;\n  /** True if a window boundary was crossed */\n  window_crossed: boolean;\n}\n\n/**\n * Updates a bucket state with a new sample.\n * Pure function - returns new state without mutating input.\n *\n * @param bucket - Current bucket state\n * @param sample - New rate limit sample\n * @param timestamp - ISO timestamp of observation\n */\nexport function updateBucket(\n  bucket: BucketState,\n  sample: RateLimitSample,\n  timestamp: string\n): UpdateResult {\n  // Check if reset changed (window boundary)\n  if (sample.reset !== bucket.last_reset) {\n    // New window: include post-reset used count\n    return {\n      bucket: {\n        last_reset: sample.reset,\n        last_used: sample.used,\n        total_used: bucket.total_used + sample.used,\n        windows_crossed: bucket.windows_crossed + 1,\n        anomalies: bucket.anomalies,\n        last_seen_ts: timestamp,\n        limit: sample.limit,\n        remaining: sample.remaining,\n      },\n      delta: sample.used,\n      anomaly: false,\n      window_crossed: true,\n    };\n  }\n\n  // Same window: calculate delta\n  const delta = sample.used - bucket.last_used;\n\n  if (delta < 0) {\n    // Anomaly: used decreased without reset change\n    return {\n      bucket: {\n        ...bucket,\n        last_used: sample.used,\n        anomalies: bucket.anomalies + 1,\n        last_seen_ts: timestamp,\n        limit: sample.limit,\n        remaining: sample.remaining,\n      },\n      delta: 0,\n      anomaly: true,\n      window_crossed: false,\n    };\n  }\n\n  // Normal case: accumulate delta\n  return {\n    bucket: {\n      ...bucket,\n      last_used: sample.used,\n      total_used: bucket.total_used + delta,\n      last_seen_ts: timestamp,\n      limit: sample.limit,\n      remaining: sample.remaining,\n    },\n    delta,\n    anomaly: false,\n    window_crossed: false,\n  };\n}\n\n// -----------------------------------------------------------------------------\n// State factory\n// -----------------------------------------------------------------------------\n\n/**\n * Creates initial reducer state.\n */\nexport function createInitialState(): ReducerState {\n  return {\n    buckets: {},\n    started_at_ts: new Date().toISOString(),\n    stopped_at_ts: null,\n    poller_started_at_ts: null,\n    interval_seconds: POLL_INTERVAL_SECONDS,\n    poll_count: 0,\n    poll_failures: 0,\n    last_error: null,\n  };\n}\n\n// -----------------------------------------------------------------------------\n// Full reducer\n// -----------------------------------------------------------------------------\n\nexport interface ReduceResult {\n  /** Updated global state */\n  state: ReducerState;\n  /** Per-bucket update results */\n  updates: Record<string, UpdateResult>;\n}\n\n/**\n * Processes a full rate limit response and updates state.\n * Pure function - returns new state without mutating input.\n *\n * @param state - Current reducer state\n * @param response - Rate limit API response\n * @param timestamp - ISO timestamp of observation\n */\nexport function reduce(\n  state: ReducerState,\n  response: RateLimitResponse,\n  timestamp: string\n): ReduceResult {\n  const newBuckets: Record<string, BucketState> = { ...state.buckets };\n  const updates: Record<string, UpdateResult> = {};\n\n  // Process each bucket in the response\n  for (const [name, sample] of Object.entries(response.resources)) {\n    const existingBucket = state.buckets[name];\n\n    if (!existingBucket) {\n      // New bucket: initialize\n      const bucket = initBucket(sample, timestamp);\n      newBuckets[name] = bucket;\n      updates[name] = {\n        bucket,\n        delta: 0,\n        anomaly: false,\n        window_crossed: false,\n      };\n    } else {\n      // Existing bucket: update\n      const result = updateBucket(existingBucket, sample, timestamp);\n      newBuckets[name] = result.bucket;\n      updates[name] = result;\n    }\n  }\n\n  return {\n    state: {\n      ...state,\n      buckets: newBuckets,\n      poll_count: state.poll_count + 1,\n    },\n    updates,\n  };\n}\n\n/**\n * Records a poll failure in state.\n * Pure function - returns new state.\n */\nexport function recordFailure(state: ReducerState, error: string): ReducerState {\n  return {\n    ...state,\n    poll_failures: state.poll_failures + 1,\n    last_error: error,\n  };\n}\n\n/**\n * Marks state as stopped.\n */\nexport function markStopped(state: ReducerState): ReducerState {\n  return {\n    ...state,\n    stopped_at_ts: new Date().toISOString(),\n  };\n}\n","const __WEBPACK_NAMESPACE_OBJECT__ = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"fs\");","/**\n * Path Resolver\n * Layer: infra\n *\n * Provided ports:\n *   - paths.statePath\n *   - paths.pidPath\n *\n * Resolves paths within $RUNNER_TEMP for state persistence.\n */\n\nimport * as path from 'path';\nimport { STATE_DIR_NAME, STATE_FILE_NAME, PID_FILE_NAME } from './types';\n\n// -----------------------------------------------------------------------------\n// Port: paths.statePath\n// -----------------------------------------------------------------------------\n\n/**\n * Returns the absolute path to the state directory.\n * Creates the path string only; does not create the directory.\n *\n * @throws Error if RUNNER_TEMP is not set\n */\nexport function getStateDir(): string {\n  const runnerTemp = process.env['RUNNER_TEMP'];\n  if (!runnerTemp) {\n    throw new Error('RUNNER_TEMP environment variable is not set');\n  }\n  return path.join(runnerTemp, STATE_DIR_NAME);\n}\n\n/**\n * Returns the absolute path to state.json\n */\nexport function getStatePath(): string {\n  return path.join(getStateDir(), STATE_FILE_NAME);\n}\n\n// -----------------------------------------------------------------------------\n// Port: paths.pidPath\n// -----------------------------------------------------------------------------\n\n/**\n * Returns the absolute path to poller.pid\n */\nexport function getPidPath(): string {\n  return path.join(getStateDir(), PID_FILE_NAME);\n}\n\n// -----------------------------------------------------------------------------\n// Helpers\n// -----------------------------------------------------------------------------\n\n/**\n * Returns the path for atomic write temporary file\n */\nexport function getStateTmpPath(): string {\n  return path.join(getStateDir(), `${STATE_FILE_NAME}.tmp`);\n}\n","/**\n * State Manager\n * Layer: core\n *\n * Provided ports:\n *   - state.read\n *   - state.write\n *\n * Manages persistent state in $RUNNER_TEMP.\n * Uses atomic rename for safe writes.\n */\n\nimport * as fs from 'fs';\nimport type { ReducerState } from './types';\nimport { getStateDir, getStatePath, getStateTmpPath } from './paths';\n\n// -----------------------------------------------------------------------------\n// Port: state.read\n// -----------------------------------------------------------------------------\n\nexport interface ReadStateResult {\n  success: true;\n  state: ReducerState;\n}\n\nexport interface ReadStateError {\n  success: false;\n  error: string;\n  /** True if file doesn't exist (expected for first read) */\n  notFound: boolean;\n}\n\nexport type ReadStateOutcome = ReadStateResult | ReadStateError;\n\n/**\n * Reads reducer state from disk.\n *\n * @returns State or error with details\n */\nexport function readState(): ReadStateOutcome {\n  const statePath = getStatePath();\n\n  try {\n    const content = fs.readFileSync(statePath, 'utf-8');\n    const parsed = JSON.parse(content) as unknown;\n\n    // TODO: Validate parsed state has correct shape\n    // For now, trust the structure\n    if (!isValidState(parsed)) {\n      return {\n        success: false,\n        error: 'Invalid state structure',\n        notFound: false,\n      };\n    }\n\n    return { success: true, state: parsed };\n  } catch (err) {\n    const error = err as NodeJS.ErrnoException;\n    if (error.code === 'ENOENT') {\n      return {\n        success: false,\n        error: 'State file not found',\n        notFound: true,\n      };\n    }\n    return {\n      success: false,\n      error: `Failed to read state: ${error.message}`,\n      notFound: false,\n    };\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Port: state.write\n// -----------------------------------------------------------------------------\n\nexport interface WriteStateResult {\n  success: true;\n}\n\nexport interface WriteStateError {\n  success: false;\n  error: string;\n}\n\nexport type WriteStateOutcome = WriteStateResult | WriteStateError;\n\n/**\n * Writes reducer state to disk atomically.\n * Creates state directory if it doesn't exist.\n * Cleans up temp file on failure to prevent orphaned files.\n *\n * @param state - State to persist\n */\nexport function writeState(state: ReducerState): WriteStateOutcome {\n  const stateDir = getStateDir();\n  const statePath = getStatePath();\n  const tmpPath = getStateTmpPath();\n\n  try {\n    // Ensure directory exists\n    fs.mkdirSync(stateDir, { recursive: true });\n\n    // Write to temp file\n    const content = JSON.stringify(state, null, 2);\n    fs.writeFileSync(tmpPath, content, 'utf-8');\n\n    // Atomic rename\n    fs.renameSync(tmpPath, statePath);\n\n    return { success: true };\n  } catch (err) {\n    // Clean up temp file on failure to prevent orphaned files\n    try {\n      fs.unlinkSync(tmpPath);\n    } catch {\n      // Ignore cleanup errors - file may not exist\n    }\n    const error = err as Error;\n    return {\n      success: false,\n      error: `Failed to write state: ${error.message}`,\n    };\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Validation\n// -----------------------------------------------------------------------------\n\n/**\n * Validates that parsed JSON has the ReducerState shape.\n * Handles missing fields gracefully per spec (W4).\n */\nexport function isValidState(obj: unknown): obj is ReducerState {\n  if (!isARealObject(obj)) {\n    return false;\n  }\n\n    // Required fields\n  if (!isARealObject(obj['buckets'])) {\n    return false;\n  }\n  if (typeof obj['started_at_ts'] !== 'string') {\n    return false;\n  }\n  if (typeof obj['interval_seconds'] !== 'number') {\n    return false;\n  }\n  if (typeof obj['poll_count'] !== 'number') {\n    return false;\n  }\n  if (typeof obj['poll_failures'] !== 'number') {\n    return false;\n  }\n\n  // Optional fields: must be string | null\n  if (!isStringOrNull(obj['stopped_at_ts'])) {\n    return false;\n  }\n  if (!isStringOrNull(obj['poller_started_at_ts'])) {\n    return false;\n  }\n  if (!isStringOrNull(obj['last_error'])) {\n    return false;\n  }\n\n  return true;\n}\n\n// -----------------------------------------------------------------------------\n// PID file management\n// -----------------------------------------------------------------------------\n\nimport { getPidPath } from './paths';\nimport { isARealObject, isStringOrNull } from './utils';\n\n/**\n * Writes the poller PID to disk.\n */\nexport function writePid(pid: number): WriteStateOutcome {\n  const pidPath = getPidPath();\n  const stateDir = getStateDir();\n\n  try {\n    fs.mkdirSync(stateDir, { recursive: true });\n    fs.writeFileSync(pidPath, String(pid), 'utf-8');\n    return { success: true };\n  } catch (err) {\n    const error = err as Error;\n    return {\n      success: false,\n      error: `Failed to write PID: ${error.message}`,\n    };\n  }\n}\n\n/**\n * Reads the poller PID from disk.\n */\nexport function readPid(): number | null {\n  const pidPath = getPidPath();\n\n  try {\n    const content = fs.readFileSync(pidPath, 'utf-8');\n    const pid = parseInt(content.trim(), 10);\n    return isNaN(pid) ? null : pid;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Removes the PID file.\n */\nexport function removePid(): void {\n  const pidPath = getPidPath();\n  try {\n    fs.unlinkSync(pidPath);\n  } catch {\n    // Ignore errors - file may not exist\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Startup verification\n// -----------------------------------------------------------------------------\n\nconst STARTUP_TIMEOUT_MS = 5000;\nconst STARTUP_CHECK_INTERVAL_MS = 100;\n\nexport interface VerifyStartupResult {\n  success: true;\n}\n\nexport interface VerifyStartupError {\n  success: false;\n  error: string;\n}\n\nexport type VerifyStartupOutcome = VerifyStartupResult | VerifyStartupError;\n\n/**\n * Waits for the poller to signal startup by setting poller_started_at_ts.\n *\n * The poller writes this timestamp immediately on startup, before any API calls.\n * This confirms:\n *   - Process spawned successfully\n *   - Environment variables were read\n *   - File I/O is working\n *\n * @param timeoutMs - Maximum time to wait (default 5000ms)\n * @returns Success or error with details\n */\nexport async function verifyPollerStartup(\n  timeoutMs: number = STARTUP_TIMEOUT_MS\n): Promise<VerifyStartupOutcome> {\n  const startTime = Date.now();\n\n  while (Date.now() - startTime < timeoutMs) {\n    const result = readState();\n\n    if (result.success && result.state.poller_started_at_ts !== null) {\n      return { success: true };\n    }\n\n    await sleep(STARTUP_CHECK_INTERVAL_MS);\n  }\n\n  return {\n    success: false,\n    error: `Poller did not signal startup within ${timeoutMs}ms`,\n  };\n}\n\nfunction sleep(ms: number): Promise<void> {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n","/**\n * Poller Process\n * Layer: poller\n *\n * Provided ports:\n *   - poller.spawn\n *   - poller.kill\n *\n * Background process that polls /rate_limit and updates state.\n * Runs as a detached child process.\n *\n * When run directly (as child process entry):\n *   - Reads config from environment\n *   - Polls at interval\n *   - Updates state file atomically\n *   - Handles SIGTERM for graceful shutdown\n */\n\nimport { spawn, ChildProcess } from 'child_process';\nimport * as path from 'path';\nimport type { ReducerState } from './types';\nimport { POLL_INTERVAL_SECONDS, MAX_LIFETIME_MS } from './types';\nimport { fetchRateLimit } from './github';\nimport { reduce, recordFailure, createInitialState, markStopped } from './reducer';\nimport { readState, writeState } from './state';\n\n// -----------------------------------------------------------------------------\n// Port: poller.spawn\n// -----------------------------------------------------------------------------\n\nexport interface SpawnResult {\n  success: true;\n  pid: number;\n}\n\nexport interface SpawnError {\n  success: false;\n  error: string;\n}\n\nexport type SpawnOutcome = SpawnResult | SpawnError;\n\n/**\n * Spawns the poller as a detached background process.\n *\n * @param token - GitHub token for API calls\n * @returns PID of spawned process or error\n */\nexport function spawnPoller(token: string): SpawnOutcome {\n  try {\n    // Resolve path to bundled poller entry\n    // ncc bundles to dist/poller/index.js\n    const actionPath = process.env['GITHUB_ACTION_PATH'];\n    const baseDir = actionPath ? path.resolve(actionPath, 'dist') : path.dirname(process.argv[1] ?? '');\n    const pollerEntry = path.resolve(baseDir, 'poller', 'index.js');\n\n    const child: ChildProcess = spawn(\n      process.execPath,\n      [pollerEntry],\n      {\n        detached: true,\n        stdio: 'ignore',\n        env: {\n          ...process.env,\n          GITHUB_API_MONITOR_TOKEN: token,\n          GITHUB_API_MONITOR_INTERVAL: String(POLL_INTERVAL_SECONDS),\n        },\n      }\n    );\n\n    // Allow parent to exit without waiting\n    child.unref();\n\n    if (!child.pid) {\n      return { success: false, error: 'Failed to get child PID' };\n    }\n\n    return { success: true, pid: child.pid };\n  } catch (err) {\n    const error = err as Error;\n    return { success: false, error: `Failed to spawn poller: ${error.message}` };\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Port: poller.kill\n// -----------------------------------------------------------------------------\n\nexport interface KillResult {\n  success: true;\n  /** True if SIGKILL was needed after SIGTERM timeout */\n  escalated?: boolean;\n}\n\nexport interface KillError {\n  success: false;\n  error: string;\n  /** True if process was not found (may have already exited) */\n  notFound: boolean;\n}\n\nexport type KillOutcome = KillResult | KillError;\n\nconst KILL_TIMEOUT_MS = 3000;\nconst KILL_CHECK_INTERVAL_MS = 100;\n\n/**\n * Kills the poller process by PID.\n * Sends SIGTERM for graceful shutdown.\n *\n * @param pid - Process ID to kill\n */\nexport function killPoller(pid: number): KillOutcome {\n  try {\n    // Check if process exists\n    process.kill(pid, 0);\n\n    // Send SIGTERM\n    process.kill(pid, 'SIGTERM');\n\n    return { success: true };\n  } catch (err) {\n    const error = err as NodeJS.ErrnoException;\n    if (error.code === 'ESRCH') {\n      return {\n        success: false,\n        error: 'Process not found',\n        notFound: true,\n      };\n    }\n    return {\n      success: false,\n      error: `Failed to kill poller: ${error.message}`,\n      notFound: false,\n    };\n  }\n}\n\n/**\n * Kills poller with verification and SIGKILL escalation.\n * Sends SIGTERM, waits for exit, escalates to SIGKILL if needed.\n */\nexport async function killPollerWithVerification(pid: number): Promise<KillOutcome> {\n  // Check if process exists\n  if (!isProcessRunning(pid)) {\n    return { success: false, error: 'Process not found', notFound: true };\n  }\n\n  // Send SIGTERM\n  try {\n    process.kill(pid, 'SIGTERM');\n  } catch (err) {\n    const error = err as NodeJS.ErrnoException;\n    if (error.code === 'ESRCH') {\n      return { success: false, error: 'Process not found', notFound: true };\n    }\n    return { success: false, error: `Failed to send SIGTERM: ${error.message}`, notFound: false };\n  }\n\n  // Wait for process to die\n  const startTime = Date.now();\n  while (Date.now() - startTime < KILL_TIMEOUT_MS) {\n    await sleep(KILL_CHECK_INTERVAL_MS);\n    if (!isProcessRunning(pid)) {\n      return { success: true, escalated: false };\n    }\n  }\n\n  // Escalate to SIGKILL\n  try {\n    process.kill(pid, 'SIGKILL');\n    await sleep(KILL_CHECK_INTERVAL_MS);\n    if (!isProcessRunning(pid)) {\n      return { success: true, escalated: true };\n    }\n    return { success: false, error: 'Process survived SIGKILL', notFound: false };\n  } catch (err) {\n    const error = err as NodeJS.ErrnoException;\n    if (error.code === 'ESRCH') {\n      return { success: true, escalated: true }; // Died between check and kill\n    }\n    return { success: false, error: `Failed to send SIGKILL: ${error.message}`, notFound: false };\n  }\n}\n\nfunction isProcessRunning(pid: number): boolean {\n  try {\n    process.kill(pid, 0);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction sleep(ms: number): Promise<void> {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\n\n// -----------------------------------------------------------------------------\n// Poller main loop (when run as child process)\n// -----------------------------------------------------------------------------\n\n/**\n * Main polling loop.\n * Runs indefinitely until SIGTERM received.\n *\n * Startup sequence:\n *   1. Read or create initial state\n *   2. Write state immediately (signals \"alive\" to parent)\n *   3. Begin polling loop\n *\n * Shutdown sequence (SIGTERM):\n *   1. Write current state immediately\n *   2. Exit with code 0\n *\n * The parent process (main.ts) waits for the state file to confirm\n * the poller started successfully before proceeding.\n */\nasync function runPollerLoop(token: string, intervalSeconds: number): Promise<void> {\n  let state: ReducerState;\n  const startTimeMs = Date.now();\n\n  // Handle graceful shutdown - write state immediately before exiting\n  process.on('SIGTERM', () => {\n    if (state) {\n      writeState(state);\n    }\n    process.exit(0);\n  });\n\n  // Initial state or read existing\n  const stateResult = readState();\n\n  if (stateResult.success) {\n    state = stateResult.state;\n  } else {\n    state = createInitialState();\n  }\n\n  // Signal alive: set timestamp and write state so parent can detect startup\n  state = { ...state, poller_started_at_ts: new Date().toISOString() };\n  writeState(state);\n\n  // Initial poll immediately\n  state = await performPoll(state, token);\n\n  // Polling loop (runs until SIGTERM or max lifetime exceeded)\n  while (true) {\n    // Defense-in-depth: exit if max lifetime exceeded\n    const elapsedMs = Date.now() - startTimeMs;\n    if (elapsedMs >= MAX_LIFETIME_MS) {\n      console.error(\n        `Poller exceeded max lifetime (${MAX_LIFETIME_MS}ms). ` +\n        `Exiting as safety measure.`\n      );\n      state = markStopped(state);\n      writeState(state);\n      process.exit(0);\n    }\n\n    await sleep(intervalSeconds * 1000);\n    state = await performPoll(state, token);\n  }\n}\n\n/**\n * Performs a single poll and updates state.\n */\nasync function performPoll(state: ReducerState, token: string): Promise<ReducerState> {\n  const timestamp = new Date().toISOString();\n  const result = await fetchRateLimit(token);\n\n  if (!result.success) {\n    const newState = recordFailure(state, result.error);\n    writeState(newState);\n    return newState;\n  }\n\n  const { state: newState } = reduce(state, result.data, timestamp);\n  writeState(newState);\n  return newState;\n}\n\n// -----------------------------------------------------------------------------\n// Child process entry point\n// -----------------------------------------------------------------------------\n\n/**\n * Entry point when run as child process.\n * Exported for use by poller-entry.ts\n */\nexport async function main(): Promise<void> {\n  const token = process.env['GITHUB_API_MONITOR_TOKEN'];\n  const intervalStr = process.env['GITHUB_API_MONITOR_INTERVAL'];\n\n  if (!token) {\n    console.error('GITHUB_API_MONITOR_TOKEN not set');\n    process.exit(1);\n  }\n\n  const interval = intervalStr ? parseInt(intervalStr, 10) : POLL_INTERVAL_SECONDS;\n\n  await runPollerLoop(token, interval);\n}\n\n// Entry point moved to poller-entry.ts for ESM compatibility\n// See: poller-entry.ts is built as dist/poller/index.js\n","/**\n * Poller Entry Point\n *\n * Separate entry file for ESM compatibility.\n * The require.main === module pattern doesn't work with ncc ESM bundling,\n * so we use a dedicated entry file that unconditionally calls main().\n *\n * Built as: dist/poller/index.js\n */\n\nimport { main } from './poller';\n\nmain().catch((err) => {\n  console.error('Poller error:', err);\n  process.exit(1);\n});\n"],"names":[],"sourceRoot":""}